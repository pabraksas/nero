# Прокачиваем исследователя
#sci #skill #python

## **Проходим курс занятий по книге "Изучение сложных систем с помощью питон"** с целью расширить навыки программирования на языке питон на область науки и научных инструментов.
#### книга несложная. даётся общий обзор концепций и методов изучения/анализа разных проблем в разных областях науки.

>[!info] [Изучение сложных систем с помощью питон]()
> > [!abstract]- Аллен Дауни (2019)
> > 
> > Наука о сложных системах – это междисциплинарная область на стыке математики, информатики и естествознания, которая фокусируется на сложных системах, представляющих собой системы со множеством взаимодействующих компонентов.
> > Одним из основных инструментов науки о сложных системах являются дискретные модели, включая сети и графы, клеточные автоматы и агентное моделирование.
> > Наука о сложных системах полезна, особенно если необходимо объяснить поведение природных и социальных систем, она обеспечивает разнообразный и адаптируемый инструментарий моделирования, позволяет применить навыки программирования и поразмыслить над фундаментальными вопросами философии науки. В книге приводится код, математические тексты и пояснения, необходимые для понимания работы моделей.
> 
> > [!example] Содержание:
> > ###### Глава 1. Наука о сложных системах
> > ###### Глава 2. Графы
> > ###### Глава 3. Графы «Мир тесен»
> > ###### Глава 4. Безмасштабные сети
> > ###### Глава 5. Клеточные автоматы
> > ###### Глава 6. Игра «Жизнь»
> > ###### Глава 8. Самоорганизованная критичность
> > ###### Глава 9. Агент-ориентированные модели
> > ###### Глава 10. Стаи, стада и пробки
> > ###### Глава 11. Эволюция
> > ###### Глава 12. Эволюция кооперации
> > 
>
>

---

## ЗА НЕДЕЛЮ:
1. прочитываем одну главу
2. выполняем задания в конце главы
3. онлайн встреча (групповой созвон), обсуждение, вопросы

## <font color="#ff0000">знание языка python обязательно!</font>
## <font color="#00b050">участие бесплатно!</font>

для записи в группу пишите в телеграм: [@pabraxaz](https://pabraxaz.t.me/)

---
*если формат найдёт своего поклонника, продолжим на другие подобные темы. например на языке Julia:*

>[!info] [Алгоритмы принятия решений]()
>
> > [!abstract]- Кохендерфер М., Уилер Т., Рэй К. (2023)
> >  пер. с англ. В. С. Яценкова. – М.: ДМК Пресс,  - 2023.  
> > – 684 с.: ил. ISBN 978-5-93700-187-0
> > 
> > Книга представляет собой введение в теорию алгоритмов принятия решений в условиях неопределенности, включая формулировки основных математических задачи методы их решения. Рассмотрены современные методы снижения вычислительной нагрузки и поиска оптимальных стратегий в различных сценариях – от простых регуляторов до стохастических многоагентных систем. Основное внимание уделяется планированию и обучению с подкреплением, хотя некоторые из представленных методов основаны на элементах обучения с учителем и оптимизации. Алгоритмы реализованы на языке программирования Julia.
> > Издание предназначено специалистам в области искусственного интеллекта и систем принятия решений, а также может быть полезно студентам и аспирантам.
> > 
>
>
> > [!example] Содержание:
> >
1 Введение
1.1. Принятие решений
1.2. Области применения
1.2.1. Предотвращение столкновения самолетов
1.2.2. Автоматизированное вождение
1.2.3. Скрининг рака молочной железы
1.2.4. Доля инвестиций и распределение портфеля
1.2.5. Распределенное наблюдение за лесными пожарами
1.2.6. Исследование Марса
1.3. Методы создания агентов
1.3.1. Явное программирование
1.3.2. Обучение с учителем
1.3.3. Оптимизация
1.3.4. Планирование
1.3.5. Обучение с подкреплением
1.4. История автоматизации принятия решений
1.4.1. Экономика
1.4.2. Психология
1.4.3. Нейробиология
1.4.4. Информатика
1.4.5. Инженерия
1.4.6. Математика
1.4.7. Исследование операций
1.5. Воздействие на общество
1.6. Краткий обзор содержания книги
1.6.1. Вероятностное рассуждение
1.6.2. Многостадийные задачи
1.6.3. Неопределенность модели
1.6.4. Неопределенность состояния
1.6.5. Мультиагентные системы
> >
Часть I. Вероятностные рассуждения
2	Формальное представление неопределенности
2.1. Степени доверия и вероятности
2.2. Распределения вероятностей
2.2.1. Дискретные распределения вероятностей
2.2.2. Непрерывные распределения вероятностей
2.3. Совместные распределения
2.3.1. Дискретные совместные распределения
2.3.2. Непрерывное совместное распределение
2.4. Условные распределения
2.4.1. Дискретные модели условных распределений
2.4.2. Условные модели Гаусса
2.4.3. Линейные модели Гаусса
2.4.4. Условные линейные модели Гаусса
2.4.5. Сигмовидные модели
2.4.6. Детерминированные переменные
2.5. Байесовские сети
2.6. Условная независимость
3 Вероятностный вывод
3.1. Вывод в байесовских сетях
3.2. Вывод в наивных байесовских моделях
3.3. Исключение переменной суммированием-перемножением
3.4. Распространение доверия
3.5. Вычислительная сложность
3.6. Прямая выборка
3.7. Выборка, взвешенная по правдоподобию
3.8. Выборка Гиббса
3.9. Вывод в гауссовых моделях
4 Параметрическое обучение
4.1. Обучение по критерию максимального правдоподобия
4.1.1. Оценки максимального правдоподобия для категориальных распределений
4.1.2. Оценки максимального правдоподобия для распределений
Гаусса
4.1.3. Оценки максимального правдоподобия для байесовских сетей
4.2. Байесовское параметрическое обучение
4.2.1. Байесовское обучение для бинарных распределений
4.2.2. Байесовское обучение для категориальных распределений
4.2.3. Байесовское обучение для байесовских сетей
4.3. Непараметрическое обучение
4.4. Обучение с отсутствующими данными
4.4.1. Подстановка данных
4.4.2. Алгоритм ожидания-максимизации
5 Структурное обучение
5.1. Оценка байесовской сети
5.2. Поиск ориентированного графа
5.3. Марковские классы эквивалентности
5.4. Поиск частично ориентированного графа
6 Простые решения
6.1. Ограничения рациональных предпочтений
6.2. Функции полезности
6.3. Выявление полезности
6.4. Принцип максимальной ожидаемой полезности
6.5. Сети принятия решений
6.6. Полезность информации
6.7. Иррациональность
> >
Часть II. Задачи последовательного принятия решений
7 Методы точного решения
7.1. Марковские процессы принятия решений
7.2. Оценка стратегии
7.3. Нахождение стратегии через функцию полезности
7.4. Итерация по стратегиям
7.5. Итерация по критерию
7.6. Асинхронная итерация по критерию
7.7. Представление задачи в виде линейной программы
7.8. Линейные системы с квадратичным вознаграждением
8	Приближенное вычисление функции полезности
8.1. Параметрические представления
8.2. Аппроксимация по ближайшему соседу
8.3. Ядерное сглаживание
8.4. Линейная интерполяция
8.5. Симплексная интерполяция
8.6. Линейная регрессия
8.7. Регрессия на основе нейронной сети
9 Онлайн-планирование
9.1. Планирование с отступающим горизонтом
9.2. Стратегия развертывания
9.3. Прямой поиск
9.4. Метод ветвей и границ
9.5. Разреженная выборка
9.6. Поиск по дереву Монте-Карло
9.7. Эвристический поиск
9.8. Эвристический поиск c разметкой
9.9. Планирование с открытым контуром
9.9.1. Прогнозирующее управление с детерминированной моделью
9.9.2. Робастное прогностическое управление
9.9.3. Многовариантное прогностическое управление
10 Поиск стратегии
10.1. Приблизительная оценка стратегии
10.2. Локальный поиск
10.3. Генетические алгоритмы
10.4. Метод перекрестной энтропии
10.5. Эволюционные стратегии
10.6. Изотропные эволюционные стратегии
11 Нахождение градиента стратегии
11.1. Конечная разность
11.2. Градиент регрессии
11.3. Отношение правдоподобия
11.4. Предстоящее вознаграждение
11.5. Вычитание базисного значения
12 Оптимизация методом градиентного спуска по стратегиям
12.1. Обновление стратегии методом градиентного подъема
12.2. Ограниченное обновление градиента
12.3. Метод натурального градиента
12.4. Метод поиска в доверительной области
12.5. Зажатие замещенной цели
13 Методы «актор–критик»
13.1. Определение актора и критика
13.2. Обобщенная оценка преимуществ
13.3. Градиент детерминированной стратегии
13.4. Метод «актор–критик» с поиском по дереву Монте-Карло
14 Проверка стратегии
14.1. Оценка показателей качества стратегии
14.2. Моделирование редких событий
14.3. Анализ робастности системы
14.4. Анализ компромиссов
14.5. Состязательный анализ
> >
Часть III. Неопределенность модели
15 Исследование среды и использование знаний
15.1. Задача однорукого бандита
15.2. Оценка байесовской модели
15.3. Стратегии ненаправленного исследования
15.4. Стратегии направленного исследования ﻿
15.5. Оптимальные стратегии исследования
15.6. Исследование с несколькими состояниями
16 Методы на основе моделей
16.1. Модели максимального правдоподобия
16.2. Схемы обновления модели
16.2.1. Полное обновление
16.2.2. Рандомизированное обновление
16.2.3. Приоритетный механизм обновления
16.3. Исследование
16.4. Байесовские методы
16.5. Адаптивные по Байесу марковские процессы принятия решений
16.6. Апостериорная выборка
17 Свободные методы обучения с подкреплением
17.1. Инкрементное вычисление среднего значения распределения
17.2. Q-обучение
17.3. Алгоритм SARSA
17.4. Следы приемлемости
17.5. Формирование вознаграждения
17.6. Аппроксимация функции полезности действия
17.7. Воспроизведение опыта
18 Имитационное обучение
18.1. Поведенческое копирование
18.2. Агрегация наборов данных
18.3. Итеративное обучение путем стохастического смешивания
18.4. Обратное обучение с подкреплением с максимальной разницей
18.5. Обратное обучение с подкреплением с максимальной энтропией
18.6. Генеративно-состязательное имитационное обучение
> >
Часть IV. Неопределенность состояния. 
19 Убеждения
19.1. Начальные убеждения
19.2. Фильтр дискретных состояний
19.3. Фильтр Калмана
19.4. Расширенный фильтр Калмана
19.5. Сигма-точечный фильтр Калмана
19.6. Парциальный фильтр
19.7. Внесение частиц
20 Точное планирование с использованием убеждений-состояний
20.1. MDP убеждений-состояний
20.2. Условные планы
20.3. Альфа-векторы
20.4. Сокращение
20.5. Итерация по полезности
20.6. Линейные стратегии
21 Офлайн-планирование с использованием убеждений-состояний
21.1. Аппроксимация полностью наблюдаемой полезности
21.2. Метод быстрой инфограницы
21.3. Методы быстрой оценки снизу
21.4. Точечная итерация по полезности
21.5. Рандомизированная точечная итерация по полезности
21.6. Пилообразная оценка сверху
21.7. Выбор точек в наборе убеждений
21.8. Пилообразный эвристический поиск
21.9. Триангулированные функции полезности
22 Онлайн-планирование с использованием убеждений-состояний
22.1. Предпросмотр с развертываниями
22.2. Прямой поиск
22.3. Метод ветвей и границ
22.4. Разреженная выборка
22.5. Поиск по дереву Монте-Карло
22.6. Поиск по детерминированному разреженному дереву
22.7. Эвристический поиск на основе разности границ
23 Понятие контроллера
23.1. Контроллеры
23.2. Итерация по стратегиям
23.3. Нелинейное программирование
23.4. Градиентный подъем
> >
Часть V. Многоагентные системы
24 Логический вывод в многоагентных системах. 
24.1. Простые игры
24.2. Модели откликов
24.2.1. Наилучший отклик
24.2.2. Отклик softmax
24.3. Равновесие доминирующей стратегии
24.4. Равновесие Нэша
24.5. Согласованное равновесие
24.6. Итеративный поиск лучшего отклика
24.7. Иерархическая форма модели softmax
24.8. Фиктивная игра
24.9. Градиентный подъем
25 Последовательные задачи. 
25.1. Марковские игры
25.2. Модели отклика
25.2.1. Наилучший отклик
25.2.2. Стратегия отклика softmax
25.3. Равновесие Нэша
25.4. Фиктивная марковская игра
25.5. Градиентный подъем
25.6. Q-обучение Нэша
26 Неопределенность состояния
26.1. Частично наблюдаемые марковские игры
26.2. Оценка стратегии
26.2.1. Оценка условных планов
26.2.2. Оценка стохастических контроллеров
26.3. Равновесие Нэша
26.4. Динамическое программирование
27 Совместные действия агентов
27.1. Децентрализованные частично наблюдаемые марковские процессы
принятия решений
27.2. Подклассы
27.3. Динамическое программирование
27.4. Итерация по наилучшим откликам
27.5. Эвристический поиск
27.6. Нелинейное программирование
> >
> -

---

- [Python для сложных задач. наука о данных и машинное обучение](Python_для_сложных_задач_наука_о_данных_и_машинное_обучение_PDFDrive.pdf)
